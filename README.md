# Gradient Descent 3D visualisations

3D visualisations of the optimisation process used to minimise the loss function of a machine learning model
- The process of gradient descent is displayed on the left showing how the optimal weights are found
- The animation on the right shows our model fitting the data based on the weights found from the gradient descent process



## Example Animations

### Minimising the Mean Squared Error loss function for linear regression:


<table>
  <tr>
    <td>On the 60<sup>th</sup> iteration<img src="images/img.png" width="500"></td>
    <td>On the 270<sup>th</sup> iteration<img src="images/img_1.png" width="500"></td>
  </tr>
    <tr>
    <td>On the 510<sup>th</sup> iteration<img src="images/img_2.png" width="500"></td>
    <td>On the 990<sup>th</sup> (final) iteration<img src="images/img_3.png" width="500"></td>
  </tr>
 </table>
 
 
### Minimising the Cross Entropy loss function for logistic regression:


<table>
  <tr>
    <td>On the 400<sup>th</sup> iteration<img src="images/img_21.png" width="500"></td>
    <td>On the 800<sup>th</sup> iteration<img src="images/img_22.png" width="500"></td>
  </tr>
    <tr>
    <td>On the 1400<sup>th</sup> iteration<img src="images/img_23.png" width="500"></td>
    <td>On the 3000<sup>th</sup> iteration<img src="images/img_24.png" width="500"></td>
  </tr>
 </table>
 
## Imports:

- Matplotlib
- NumPy
- Celluloid
- SciPy
